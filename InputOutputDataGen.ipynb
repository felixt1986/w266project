{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import urllib.request, json \n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import datetime as DT\n",
    "import ast\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Download the pre-processed tweets from dropbox\n",
    "\n",
    "access_token = 'p3Ze8FpdRTAAAAAAAAAADb9hCQ8aXXYU3A3gGM1HEXyeMrs8KI2SrA71KDmmCXte'\n",
    "dbx = dropbox.Dropbox(access_token)\n",
    "metadata, res = dbx.files_download(path=\"/Inputdata2.txt\")\n",
    "\n",
    "\n",
    "access_token2 = 'm_fKi8mWZ0AAAAAAAAAADlfzTm37f1y45k92Xpiw1B6mjT3dQqzNvKgpIUSR17uq'\n",
    "dbx2 = dropbox.Dropbox(access_token2)\n",
    "\n",
    "#Write the combined file into the drive\n",
    "with open(\"InputX.txt\", \"wb\") as f:\n",
    "    metadata, res = dbx.files_download(path=\"/Inputdata2.txt\")\n",
    "    metadata2, res2 = dbx2.files_download(path=\"/Inputdata.txt\")\n",
    "    f.write(res.content)\n",
    "    f.write(res2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Translate date of the tweet to quarter reference\n",
    "def Quarterlookup(date):\n",
    "    if date>=DT.datetime(2018,10,1):\n",
    "        return '18Q4'\n",
    "    elif date>=DT.datetime(2018,7,1):\n",
    "        return '18Q3'\n",
    "    elif date>=DT.datetime(2018,4,1):\n",
    "        return '18Q2'\n",
    "    elif date>=DT.datetime(2018,1,1):\n",
    "        return '18Q1'\n",
    "    elif date>=DT.datetime(2017,10,1):\n",
    "        return '17Q4'\n",
    "    elif date>=DT.datetime(2017,7,1):\n",
    "        return '17Q3'\n",
    "    elif date>=DT.datetime(2017,4,1):\n",
    "        return '17Q2'\n",
    "    elif date>=DT.datetime(2017,1,1):\n",
    "        return '17Q1'\n",
    "    elif date>=DT.datetime(2016,10,1):\n",
    "        return '16Q4'\n",
    "    elif date>=DT.datetime(2016,7,1):\n",
    "        return '16Q3'\n",
    "    elif date>=DT.datetime(2016,4,1):\n",
    "        return '16Q2'\n",
    "    elif date>=DT.datetime(2016,1,1):\n",
    "        return '16Q1'\n",
    "    elif date>=DT.datetime(2015,10,1):\n",
    "        return '15Q4'\n",
    "    elif date>=DT.datetime(2015,7,1):\n",
    "        return '15Q3'\n",
    "    elif date>=DT.datetime(2015,4,1):\n",
    "        return '15Q2'\n",
    "    else:\n",
    "        return '15Q1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Reading the Input X file and process it\n",
    "d=defaultdict(list)\n",
    "\n",
    "with open('InputX.txt') as f:\n",
    "    for line in f:\n",
    "        count=0\n",
    "        temp =-1\n",
    "        k,v=line.split(':',1)\n",
    "        while True:\n",
    "            \n",
    "            oldtemp=temp\n",
    "            temp=v.find(']]',temp+1)\n",
    "            if count==0:\n",
    "                d[k].append(v[oldtemp+2:temp+2]) \n",
    "            else:\n",
    "                d[k].append(v[oldtemp+4:temp+2])\n",
    "           \n",
    "             \n",
    "            count+=1\n",
    "            if temp == -1: break\n",
    "\n",
    "    \n",
    "          \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allword=set()\n",
    "for key,value in d.items():\n",
    "    for i in value:\n",
    "        for j in tokenizer.tokenize(i):\n",
    "            allword.add(j)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allword=sorted(allword)\n",
    "vocab = vocabulary.Vocabulary(allword, size=None)  # size=None means unlimited\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_np_array(example_ids, max_len=50, pad_id=0):\n",
    "\n",
    "    arr = np.full([len(example_ids), max_len], pad_id, dtype=np.int32)\n",
    "    ns = np.zeros([len(example_ids)], dtype=np.int32)\n",
    "    cpy_len = min(len(example_ids), max_len)\n",
    "\n",
    "    arr = example_ids[:cpy_len]\n",
    "    ns = cpy_len\n",
    "    return arr, ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('15Q2', [[2, 2, 4, 2, 4, 2, 2, 2680, 2, 2, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2009, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2670, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2670, 2, 2]]), ('15Q3', [[2, 2, 2, 2, 2, 2670, 2, 2, 2, 2672, 2, 7, 2, 7, 2, 2, 2, 2673, 2, 4, 2, 4, 2, 4, 2]]), ('16Q2', [[2, 2683, 2, 2, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2632, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2670, 2, 2670, 2, 2, 2]]), ('16Q3', [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2670, 2, 2, 2672, 2, 2, 7, 2, 7, 2, 7, 2, 2], [2, 2, 4, 2, 4, 2, 2, 2680, 2, 2, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2009, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]), ('16Q4', [[2, 2, 2, 2, 2632, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 9, 4, 2, 2, 2, 2, 2, 2]]), ('17Q1', [[2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 4, 2, 4, 2, 4, 2, 2, 2, 2]]), ('17Q2', [[4, 2, 2, 4, 2, 2, 2, 2, 2, 5, 2674, 2, 2, 2, 2, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2670, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2683, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2]]), ('18Q3', [[2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 4, 2, 2632, 5, 2, 2, 2670, 2, 2, 2, 2]])])\n",
      "OrderedDict([('15Q2', [50, 50]), ('15Q3', [25]), ('16Q2', [43]), ('16Q3', [46, 50]), ('16Q4', [50]), ('17Q1', [27]), ('17Q2', [34, 27]), ('18Q3', [49])])\n"
     ]
    }
   ],
   "source": [
    "##Converting the string of data into dictionary\n",
    "InputX=defaultdict(dict)\n",
    "InputN=defaultdict(dict)\n",
    "\n",
    "for key,value in d.items():\n",
    "    Inputx=defaultdict(list)\n",
    "    Inputn=defaultdict(list)\n",
    "    for value2 in value:\n",
    "        \n",
    "        temp=value2.find('), ')\n",
    "        date=value2[14:temp+3]\n",
    "        try:\n",
    "            year=int(date[1:5])\n",
    "            month=int(date[date.find(',')+2:date.find(',',date.find(',')+1)])\n",
    "            day=int(date[date.find(')')-2:date.find(')')])\n",
    "            \n",
    "            sentence, length = pad_np_array (vocab.words_to_ids(ast.literal_eval(value2[temp+3:-1])))\n",
    "            \n",
    "            Inputx[Quarterlookup(DT.datetime(year,month,day))].append(sentence)\n",
    "            Inputn[Quarterlookup(DT.datetime(year,month,day))].append(length)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    InputX[key]=OrderedDict(sorted(Inputx.items()))\n",
    "    InputN[key]=OrderedDict(sorted(Inputn.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CVSHealth': 'CVS', 'RiteAid': 'RAD', \"Conn's\": 'CONN', \"Casey's\": 'CASY', 'Kroger': 'KR', 'VillageSuperMarket': 'VLGEA', 'WeisMarkets': 'WMK', 'HavertyFurniture': 'HVT', \"Kirkland's\": 'KIRK', 'Pier1Imports': 'PIR', 'BuildersFirstSource': 'BLDR', 'HuttigBuildingProducts': 'HBP', 'LumberLiquidators': 'LL', 'TransWorldEntertainment': 'TWMC', 'MarineMax': 'HZO', 'Medifast': 'MED', 'SallyBeauty': 'SBH', \"Sotheby's\": 'BID', 'StarGasPartners': 'SGU', 'SuburbanPropanePartners': 'SPH', 'TitanMachinery': 'TITN', 'TractorSupply': 'TSCO', 'TravelCentersofAmerica': 'TA', 'Big5SportingGoods': 'BGFV', \"Dick'sSportingGoods\": 'DKS', 'HibbettSports': 'HIBB', 'Build-A-BearWorkshop': 'BBW'}\n"
     ]
    }
   ],
   "source": [
    "##List of stockname and relevant stock code\n",
    "l = [(\"CVSHealth\", \"CVS\"),\n",
    "(\"RiteAid\", \"RAD\"),\n",
    "(\"Conn's\", \"CONN\"),\n",
    "(\"Casey's\", \"CASY\"),\n",
    "(\"Kroger\", \"KR\"),\n",
    "(\"VillageSuperMarket\", \"VLGEA\"),\n",
    "(\"WeisMarkets\", \"WMK\"),\n",
    "(\"HavertyFurniture\", \"HVT\"),\n",
    "(\"Kirkland's\", \"KIRK\"),\n",
    "(\"Pier1Imports\",\"PIR\"),\n",
    "(\"BuildersFirstSource\",\"BLDR\"),\n",
    "(\"HuttigBuildingProducts\", \"HBP\"),\n",
    "(\"LumberLiquidators\", \"LL\"),\n",
    "(\"TransWorldEntertainment\", \"TWMC\"),\n",
    "(\"MarineMax\", \"HZO\"),\n",
    "(\"Medifast\", \"MED\"),\n",
    "(\"SallyBeauty\", \"SBH\"),\n",
    "(\"Sotheby's\", \"BID\"),\n",
    "(\"StarGasPartners\", \"SGU\"),\n",
    "(\"SuburbanPropanePartners\", \"SPH\"),\n",
    "(\"TitanMachinery\", \"TITN\"),\n",
    "(\"TractorSupply\",\"TSCO\"),\n",
    "(\"TravelCentersofAmerica\", \"TA\"),\n",
    "(\"Big5SportingGoods\", \"BGFV\"),\n",
    "(\"Dick'sSportingGoods\", \"DKS\"),\n",
    "(\"HibbettSports\", \"HIBB\"),\n",
    "(\"Build-A-BearWorkshop\", \"BBW\")]\n",
    "     \n",
    "all_stock = {}\n",
    "[all_stock.update({k:v}) for k,v in l]\n",
    "print(all_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the quarterly return detail from edgaronline and convert into library\n",
    "top=\"http://datafied.api.edgar-online.com/v2/corefinancials/qtr?primarysymbols=\"\n",
    "bottom=\"&appkey=asc97xrhkyu4959aptu76zxj\"\n",
    "Outputy =defaultdict(dict)\n",
    "for stockname,stock in all_stock.items():\n",
    "    check=top+stock+bottom\n",
    "    with urllib.request.urlopen(check) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "    count1=0\n",
    "    count2=0\n",
    "    end_date=[]\n",
    "    revenue_change=[]\n",
    "    last_rev=0\n",
    "\n",
    "    for key, value in data.items():\n",
    "        \n",
    "        for key2, value2 in value.items():          \n",
    "        \n",
    "            if count1!=0:  \n",
    "                for i in reversed(value2):\n",
    "                  \n",
    "                    for j in i[\"values\"]:\n",
    "                     \n",
    "                        if count2!=0:   \n",
    "                            if j[\"field\"] ==\"periodenddate\":\n",
    "                                end_date.append(Quarterlookup(DT.datetime.strptime(j['value'], '%m/%d/%Y')))\n",
    "                       \n",
    "                            ##Convert revenue into the y_label of 0 for negative growth and 1 for positive growth\n",
    "                            if j[\"field\"] ==\"totalrevenue\":\n",
    "                                revenue_cal =round(float(j['value'])/float(last_rev) - 1,3)\n",
    "                                if revenue_cal>0:\n",
    "                                    revenue_change.append(1)\n",
    "                                else:\n",
    "                                    revenue_change.append(0)\n",
    "                        else:\n",
    "                            \n",
    "                            if j[\"field\"] ==\"totalrevenue\":      \n",
    "                                last_rev=j['value']\n",
    "                              \n",
    "                    count2+=1\n",
    "            count1+=1\n",
    "            \n",
    "    ##Output will be a dictionary with stockname\n",
    "    Outputy[stockname][\"period\"]=end_date\n",
    "    Outputy[stockname][\"revenuechange\"]=revenue_change\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Outputy.txt', 'w') as f:\n",
    "    print(Outputy, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x = []\n",
    "train_n = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_n = []\n",
    "test_y = []\n",
    "\n",
    "stock =['CVSHealth', 'RiteAid', \"Conn's\", \"Casey's\", 'Kroger', 'VillageSuperMarket', 'WeisMarkets', 'HavertyFurniture', \"Kirkland's\", 'Pier1Imports', 'BuildersFirstSource', 'HuttigBuildingProducts', 'LumberLiquidators', 'TransWorldEntertainment', 'MarineMax', 'Medifast', 'SallyBeauty',\"Sotheby's\", 'StarGasPartners', 'SuburbanPropanePartners', 'TitanMachinery', 'TractorSupply', 'TravelCentersofAmerica', 'Big5SportingGoods', \"Dick'sSportingGoods\", 'HibbettSports', 'Build-A-BearWorkshop']\n",
    "quarter=['15Q1','15Q2','15Q3','15Q4','16Q1','16Q2','16Q3','16Q4','17Q1','17Q2','17Q3','17Q4','18Q1','18Q2','18Q3']\n",
    "\n",
    "for i in stock:\n",
    "    for j in range(len(quarter)):\n",
    "        try:\n",
    "            if quarter[j]=='3Q18':\n",
    "                test_x.append(InputX [i][quarter[j]])\n",
    "                test_n.append(InputN [i][quarter[j]])\n",
    "                test_y.append(Outputy [i]['revenuechange'][j])                \n",
    "               \n",
    "            else:\n",
    "                train_x.append(InputX [i][quarter[j]])\n",
    "                train_n.append(InputN [i][quarter[j]])\n",
    "                length=len(InputN [i][quarter[j]])\n",
    "           \n",
    "                train_y.append([Outputy [i]['revenuechange'][j]]*length)\n",
    "      \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[50, 50]\n",
      "[[2, 2, 4, 2, 4, 2, 2, 2680, 2, 2, 2, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2009, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2670, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 2633, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2670, 2, 2]]\n",
      "[1]\n",
      "[45]\n",
      "[[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2632, 2, 2632, 2, 2632, 2, 2632, 2, 2, 2, 2, 2, 2, 2, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])\n",
    "print(train_n[0])\n",
    "print(train_x[0])\n",
    "print(train_y[10])\n",
    "print(train_n[10])\n",
    "print(train_x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
